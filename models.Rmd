---
title: "Final document"
author: "Simon"
date: "25/11/2021"
output: html_document
---

pakker
```{r}
library(tidyverse)
library(keras)
```


```{r}
library(readxl)
data_start <- read_excel("preprocess.xlsx")
```

```{r}
data_start %<>% mutate(y= ifelse(rResult==1, "red_win","blue_win")) %>% select(- rResult, -bResult)
```


preprocess

```{r}
data = data_start %>%
  relocate(y) %>%
  select(-c(Address, baron_diff_10, baron_diff_15, baron_diff_5, inhib_diff_10, inhib_diff_5))
```

we creat training and testing data

```{r}
library(rsample)
data_split <- initial_split(data, prop = 0.75, strata = y)

data_train <- data_split  %>%  training()
data_test <- data_split %>% testing()
```


```{r}
data_recipe <- data_train %>%
  recipe(y ~.) %>%
  step_center(all_numeric(), -all_outcomes()) %>% # Centers all numeric variables to mean = 0
  step_scale(all_numeric(), -all_outcomes()) %>% # scales all numeric variables to sd = 1
  step_dummy(all_nominal(), one_hot = TRUE) %>%
  prep()
```

```{r}
x_train <- juice(data_recipe) %>% select(-starts_with('y')) %>% as.matrix()
x_test <- bake(data_recipe, new_data = data_test) %>% select(-starts_with('y')) %>% as.matrix()
```

```{r}
y_train <- juice(data_recipe)  %>% select(starts_with('y')) %>% as.matrix()
y_test <- bake(data_recipe, new_data = data_test) %>% select(starts_with('y')) %>% as.matrix()
```


```{r}
model_keras <- keras_model_sequential()
```

```{r}
model_keras %>% 
  # First hidden layer
  layer_dense(
    units              = 12, 
    activation         = "relu", 
    input_shape        = ncol(x_train)) %>% 
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  # Second hidden layer
  layer_dense(
    units              = 12, 
    activation         = "relu") %>% 
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  # Output layer
  layer_dense(
    units              = ncol(y_train), 
    activation         = "sigmoid") 
```


```{r}
model_keras %>% 
  compile(
    optimizer = "adam",
    loss = "binary_crossentropy",
    metrics = "accuracy"
  )
```


```{r}
model_keras_hist <- model_keras  %>% fit(x = x_train, 
                                         y = y_train, 
                                         epochs = 10, # How often shall we re-run the model on the whole sample
                                         batch_size = 12, # How many observations should be included in every batch
                                         validation_split = 0.25 # If we want to do a  cross-validation in the training
                                         )
```






# ANN

```{r}
model <- keras_model_sequential() %>%
  layer_dense(units = 16, activation = "relu", input_shape = ncol(x_train)) %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
```

```{r}
model %>% compile(
  optimizer = "adam",
  loss = "binary_crossentropy",
  metrics = "accuracy"
)
```


```{r}
summary(model)
```

```{r}
history_ann <- model %>% fit(
  x_train,
  y_train,
  epochs = 10,
  batch_size = 256,
  validation_split = 0.25
)
```

# RNN

```{r}
model_keras <- keras_model_sequential()
```

```{r}
model_keras %>% 
  # First hidden layer
  layer_dense(
    units              = 12, 
    activation         = "relu", 
    input_shape        = ncol(x_train)) %>% 
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  # Second hidden layer
  layer_dense(
    units              = 12, 
    activation         = "relu") %>% 
  # Dropout to prevent overfitting
  layer_dropout(rate = 0.1) %>%
  # Output layer
  layer_dense(
    units              = ncol(y_train), 
    activation         = "softmax") 
```

